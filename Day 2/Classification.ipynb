{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95wZylVUhfPg",
        "colab_type": "text"
      },
      "source": [
        "## Classification\n",
        "\n",
        "Classification is the machine learning problem of assigning a label to the datapoints. \n",
        "\n",
        "A machine learning classifier, learns an approximate mapping function $(f)$  from input variables $(X)$ to discrete output variables $(y)$.\n",
        "\n",
        "### Classifying an SMS either as spam or not spam\n",
        "\n",
        "In this tutorial, we attempt to build a binary classifer which can identify whether an sms recieved on your phone is either spam or not-spam.\n",
        "\n",
        "\n",
        "### Workflow\n",
        "\n",
        "\n",
        "*   Loading data\n",
        "*   Building model\n",
        "*   Evaluating model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE5TPDPbkcFS",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 1: Getting data ready\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "We are going to use [SMS Spam Collection](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) dataset from [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc1cduychZHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Downloading the dataset\n",
        "'''\n",
        "\n",
        "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip\n",
        "! unzip smsspamcollection.zip\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l_jPdwilyRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Loading the data into a pandas dataframe\n",
        "'''\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('SMSSpamCollection', sep='\\t', header=None)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rr2HePf7nGyf",
        "colab_type": "text"
      },
      "source": [
        "### Creating a train-test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZdZYEU1m2Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data[1], data[0], test_size=.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9oMQIXZnVVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print data.shape\n",
        "print x_train.shape\n",
        "print x_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOMwmh1Nog2U",
        "colab_type": "text"
      },
      "source": [
        "### Vectorizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVcAMKEGnc6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print x_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nty94pwJqeOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Understanding CountVectorizer\n",
        "'''\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "corpus = [\n",
        "    'This is the first document.',\n",
        "    'This document is the second document.',\n",
        "    'And this is the third one.',\n",
        "    'Is this the first document?',\n",
        "]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus) # Learn the vocabulary dictionary and return term-document matrix.\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "print(X.toarray())  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09fm8UocnwfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Vectorising the training data\n",
        "'''\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "x_train_vec = vectorizer.fit_transform(x_train)\n",
        "\n",
        "print x_train_vec.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP-pPRibrLY6",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 2: Building Model\n",
        "\n",
        "---\n",
        "\n",
        "We would like to use a **Naive Bayes model** to classify whether an SMS is spam or ham (not-spam).\n",
        "\n",
        "### Brief Explainiation\n",
        "\n",
        "* SMS1: How are you\n",
        "* SMS2: Congratulations you have won 100000\n",
        "\n",
        "$p(\\text{is_spam}=true |  \\text{ How are you}) \\approx p(How|\\text{is_spam}=true) \\times p(are|\\text{is_spam}=true)\\times p(you|\\text{is_spam}=true) \\times p(\\text{is_spam}=true)$\n",
        "\n",
        "$p(\\text{is_spam}=false |  \\text{ How are you}) \\approx p(How|\\text{is_spam}=false) \\times p(are|\\text{is_spam}=false)\\times p(you|\\text{is_spam}=false) \\times p(\\text{is_spam}=false)$\n",
        "\n",
        "Whichever is higher, classify the SMS into it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDdr_KPcp1xZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Learning the model\n",
        "'''\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(x_train_vec, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_diL7qVzxqF",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 3: Evaluating Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPZ1qyGOzXXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Testing the model\n",
        "Evaluation metric: Accuracy\n",
        "'''\n",
        "x_test_vec = vectorizer.transform(x_test)\n",
        "score = classifier.score(x_test_vec, y_test)\n",
        "print score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVvNcKHV_G3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Confusion Matrix\n",
        "'''\n",
        "from sklearn.metrics import confusion_matrix\n",
        "prediction = classifier.predict(x_test_vec)\n",
        "confusion_matrix(prediction, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpvj2JkIz1o2",
        "colab_type": "text"
      },
      "source": [
        "#### Try your own data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fb5Br28MzeO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_vec = vectorizer.transform(['Hello Grab this Offer!! With Club Mahindra Membership get Free 3N/4D Singapore Cruise Trip. Join Now !  http://p3v.in/PHNKLNKYMMP'])\n",
        "classifier.predict(x_test_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JElK9koAz6F8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_vec = vectorizer.transform(['Hey! How was this tutrial?'])\n",
        "classifier.predict(x_test_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPs_PsxF98eH",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Further notes\n",
        "\n",
        "---\n",
        "\n",
        "### K-fold cross validation \n",
        "\n",
        "Here, some part of the data has been kept aside as test data, to evaluate the performance of the model. \n",
        "\n",
        "In K-fold cross validation, the dataset is randomly split into $k$ mutually exclusive subsets. Each fold is then used once as a validation while the $k - 1$ remaining folds form the training set. Average accuracy across folds is reported. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFuSil5F0CLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Creating four folds\n",
        "kf = KFold(n_splits=4)\n",
        "\n",
        "# Reinitalizaing the classifier\n",
        "classifier = BernoulliNB()\n",
        "\n",
        "scores = []\n",
        "for train_index, test_index in kf.split(data):\n",
        "  # data for each fold\n",
        "  x_train, x_test, y_train, y_test = data[1][train_index], data[1][test_index], data[0][train_index], data[0][test_index]\n",
        "  \n",
        "  # Vectorizing it\n",
        "  vectorizer = CountVectorizer()\n",
        "  x_train_vec = vectorizer.fit_transform(x_train)\n",
        "  \n",
        "  # Fitting the model\n",
        "  classifier.fit(x_train_vec, y_train)\n",
        "  \n",
        "  # Evaluating\n",
        "  x_test_vec = vectorizer.transform(x_test)\n",
        "  score = classifier.score(x_test_vec, y_test)\n",
        "  scores.append(score)\n",
        "\n",
        "avg_score = sum(scores) / len(scores) \n",
        "print 'Average accuracy:',avg_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eWp3rqad9Nn",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Exercise\n",
        "\n",
        "---\n",
        "\n",
        "Can you try using a support vector machine to solve the same problem. Report its accuracy. \n",
        "\n",
        "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAhpHyhnD4S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}