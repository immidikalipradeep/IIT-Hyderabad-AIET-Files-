{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_Classification.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF6qOi-bCdtv",
        "colab_type": "text"
      },
      "source": [
        "## Image Classification\n",
        "\n",
        "We will use a convolutional neural network to classify images of ants and bees. \n",
        "\n",
        "We have about 120 training images each for ants and bees. There are 75 validation images for each class. \n",
        "\n",
        "We will fine-tune an ImageNet pretrained Resnet 18 to do the task.\n",
        "\n",
        "This notebook has been adapted from PyTorch's official [tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLgHIDYUFbJo",
        "colab_type": "text"
      },
      "source": [
        "### Load the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_6fYrUWJJVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "! unzip hymenoptera_data.zip\n",
        "! ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5Y_MruMBT4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import torch\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = './hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzJRLjpFF7fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print 'dataset_sizes: ', dataset_sizes\n",
        "print 'class_names: ', class_names\n",
        "print 'device: ', device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrcMXNx1LyEr",
        "colab_type": "text"
      },
      "source": [
        "### Helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDIihzK4J-2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    \n",
        "def visualize_results(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foWmZ1b_L_pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTda-on_G2z8",
        "colab_type": "text"
      },
      "source": [
        "### Define the model\n",
        "\n",
        "ResNet 18\n",
        "![ResNet 18](https://storage.googleapis.com/kaggle-datasets-images/6885/9959/d9e74a548a8cdca167b38520ac8bf405/data-original.png?t=2017-12-12-23-54-44)\n",
        "\n",
        "**Steps**:\n",
        "\n",
        "*   Remove the final FC layer\n",
        "*   Add new layer with two neurons\n",
        "*   Train only the newly added layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45f30sETGM5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time, copy\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "  \n",
        "num_final_features = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(num_final_features, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfZ3bX7DJpJ6",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry_2d5S8HiGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 25\n",
        "since = time.time()\n",
        "\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            scheduler.step()\n",
        "            model.train()  # Set model to training mode\n",
        "        else:\n",
        "            model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # backward + optimize only if in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "            phase, epoch_loss, epoch_acc))\n",
        "\n",
        "        # deep copy the model\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "\n",
        "time_elapsed = time.time() - since\n",
        "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "    time_elapsed // 60, time_elapsed % 60))\n",
        "print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "# load best model weights\n",
        "model.load_state_dict(best_model_wts)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocTZIhcfL0ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualize_results(model)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nKjONhQNDSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}